{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bd1649-aa3f-4c0c-a7a2-e9a7d07e76c8",
   "metadata": {},
   "source": [
    "# World Model Core\n",
    "*Sean Steinle, Kiya Aminfar*\n",
    "\n",
    "This notebook walks through the core aspects of world models, developing crucial pieces of code sequentially. Not that this code isn't meant for scale -- instead, this is for a demonstration of how we developed the code that we did.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Collecting Rollout Data](#Collecting-Rollout-Data)\n",
    "2. [Training the VAE](#Training-the-VAE)\n",
    "3. [Training the MDN-RNN](#Training-the-MDN-RNN)\n",
    "    - [Prepping Rollout Data for the MDN-RNN](#Prepping-Rollout-Data-for-the-MDN-RNN)\n",
    "    - [Core Training](#Core-Training)\n",
    "4. [Training the Controller](#Training-the-Controller)\n",
    "5. [Early Results](#Early-Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21544f3f-d6e2-4fda-8b1d-4e6b51e934bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7847949-423a-47be-a72d-62322c9143ee",
   "metadata": {},
   "source": [
    "## Collecting Rollout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fe9254-55f2-4148-84fc-aa3d9452e7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's begin by creating an instance of our humanoid environment and checking out what basic observations look like.\n",
    "env = gym.make('Humanoid-v5', render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47c4e48-4af5-4ca9-be13-59301b800e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((348,),\n",
       " array([ 1.40341577e+00,  1.00747925e+00,  9.73546305e-04,  1.06873046e-03,\n",
       "         9.89902476e-04, -6.37256663e-04, -9.98722132e-03,  9.16488848e-03,\n",
       "         1.23624732e-03,  6.16934287e-03, -1.01781502e-03,  2.26579802e-04,\n",
       "        -8.53127582e-03,  5.41751538e-03,  8.42231145e-03, -9.81994389e-03,\n",
       "        -6.47190204e-03,  3.45426398e-03,  7.26497597e-03,  5.73572752e-04,\n",
       "        -3.79495516e-04,  3.20711144e-03,  1.40333265e-03,  5.67002471e-03,\n",
       "        -2.19794004e-03, -3.00387444e-03, -6.42484571e-03, -5.10354813e-03,\n",
       "        -8.27921308e-03, -3.34882568e-03, -9.92115875e-04,  8.59856070e-03,\n",
       "         9.21170464e-03,  9.17586625e-03, -3.88124728e-03, -8.21228118e-03,\n",
       "        -7.77879983e-03, -4.72730843e-03, -7.29832598e-03, -7.76984730e-03,\n",
       "        -2.35701367e-03, -8.00967292e-03,  7.06535641e-03,  5.36315955e-03,\n",
       "        -9.10047111e-03,  2.30228693e+00,  2.28617233e+00,  4.45393922e-02,\n",
       "        -6.46873597e-04,  7.82475702e-02,  1.81646205e-02, -1.67780117e-01,\n",
       "        -3.67236778e-02,  4.35476832e+00,  8.90746237e+00,  9.52309353e-02,\n",
       "         9.06562926e-02,  1.14431704e-02, -2.03928930e-04,  1.15438797e-02,\n",
       "         1.55578214e-03, -5.94282412e-02, -8.07009006e-03,  4.39380413e-01,\n",
       "         2.26194671e+00,  5.78994290e-02,  4.28630852e-02,  6.53438474e-02,\n",
       "        -6.49342833e-04,  8.48818968e-03,  1.40383934e-04, -2.93192223e-01,\n",
       "        -1.55824426e-02,  1.91534706e-01,  6.61619413e+00,  2.74559416e-01,\n",
       "         2.33815836e-01,  5.30827701e-02, -9.37175915e-03, -1.67730594e-02,\n",
       "        -7.90630250e-02, -9.83936240e-02, -4.50354936e-01, -8.63570798e-01,\n",
       "         4.75175093e+00,  9.30944945e-01,  9.11579247e-01,  2.36914489e-02,\n",
       "        -3.34494124e-03, -2.16632339e-02, -1.31946794e-01, -3.92601423e-02,\n",
       "        -2.34347232e-01, -1.55584340e+00,  2.75569617e+00,  1.04897768e+00,\n",
       "         1.03713751e+00,  1.62306583e-02, -1.57996068e-03, -1.46298744e-02,\n",
       "        -1.11554413e-01, -1.91353434e-02, -1.45909113e-01, -1.35106654e+00,\n",
       "         1.76714587e+00,  2.72562414e-01,  2.30774257e-01,  5.48717263e-02,\n",
       "         1.03578744e-02, -1.87984463e-02,  8.17046335e-02, -1.07334439e-01,\n",
       "         4.58338917e-01, -8.53779508e-01,  4.75175093e+00,  9.32141739e-01,\n",
       "         9.06386098e-01,  3.14785338e-02,  5.84985581e-03, -3.33108060e-02,\n",
       "         1.54097085e-01, -5.90730427e-02,  2.72824627e-01, -1.55061563e+00,\n",
       "         2.75569617e+00,  1.05055300e+00,  1.03267297e+00,  2.35539186e-02,\n",
       "         3.98735881e-03, -2.95388226e-02,  1.38746178e-01, -3.87315551e-02,\n",
       "         1.81925167e-01, -1.34772301e+00,  1.76714587e+00,  4.31848284e-01,\n",
       "         3.31370819e-01,  1.25409942e-01,  3.21355311e-02, -4.16538053e-02,\n",
       "         1.78639434e-01,  1.07088355e-01, -4.22398389e-01,  7.21571501e-01,\n",
       "         1.66108048e+00,  3.26132794e-01,  3.44467781e-01,  1.73880494e-01,\n",
       "         7.74497830e-02, -1.53681738e-01,  1.28977032e-01,  3.35558265e-01,\n",
       "        -2.99642997e-01,  5.47348070e-01,  1.22954019e+00,  4.25495286e-01,\n",
       "         3.31372353e-01,  1.18330184e-01, -3.06959891e-02, -4.07300377e-02,\n",
       "        -1.72833122e-01,  1.04879473e-01,  4.08922790e-01,  7.21928683e-01,\n",
       "         1.66108048e+00,  3.20728607e-01,  3.42982301e-01,  1.69380721e-01,\n",
       "        -7.48875846e-02, -1.53030204e-01, -1.24894740e-01,  3.34802635e-01,\n",
       "         2.91017376e-01,  5.46067194e-01,  1.22954019e+00, -3.00208689e-03,\n",
       "        -6.42087774e-03, -5.10959009e-03,  4.34053534e-03,  4.22276592e-03,\n",
       "        -2.10499050e-03, -2.98211110e-03, -9.75364577e-03, -1.33952561e-02,\n",
       "         5.23514808e-03,  4.00386553e-03, -2.01478474e-03, -3.97410126e-03,\n",
       "        -9.75493048e-03, -1.34109966e-02,  5.23536829e-03,  3.87524513e-03,\n",
       "        -2.01816533e-03,  4.40709938e-03, -6.82719848e-04, -3.95244314e-03,\n",
       "         4.37912456e-03,  3.99866141e-03, -1.37782513e-03,  4.37737210e-03,\n",
       "         3.19812296e-03, -3.90494709e-03,  5.90648111e-03,  4.01120736e-03,\n",
       "        -1.44698238e-03,  4.37737210e-03,  3.19812296e-03, -3.90494709e-03,\n",
       "         5.90648111e-03,  4.01120736e-03, -1.44698238e-03,  4.09593221e-03,\n",
       "        -1.46235174e-02, -5.59757738e-03,  5.95512159e-03,  3.98383829e-03,\n",
       "        -2.69389228e-03,  4.12374275e-03, -7.32666281e-03, -5.45369632e-03,\n",
       "         8.83456495e-03,  3.97594183e-03, -2.84999037e-03,  4.12374275e-03,\n",
       "        -7.32666281e-03, -5.45369632e-03,  8.83456495e-03,  3.97594183e-03,\n",
       "        -2.84999037e-03, -9.34462815e-03, -7.93818461e-03, -9.94653032e-03,\n",
       "         5.96269947e-03,  8.86427989e-04, -3.18550715e-03, -9.33784911e-03,\n",
       "        -2.29350850e-03, -1.56291746e-02,  6.08575760e-03,  1.82600432e-03,\n",
       "        -2.25206173e-03,  2.77735529e-03, -5.51629953e-03,  1.55843270e-03,\n",
       "         4.98085977e-03,  7.30711416e-03, -3.07840532e-03,  2.77538637e-03,\n",
       "         9.03231342e-04,  8.00887407e-03,  5.06808547e-03,  6.25642651e-03,\n",
       "        -2.03272594e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2035ecfe-44e4-4ab0-b4bb-7213f9d50c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_position': np.float64(0.004285169441919876),\n",
       " 'y_position': np.float64(0.00480598111663944),\n",
       " 'tendon_length': array([-0.01824226,  0.00124439]),\n",
       " 'tendon_velocity': array([-0.00257102, -0.01305711]),\n",
       " 'distance_from_origin': np.float64(0.0064389542349250145)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de32bf7-40c6-40e3-bbd3-b1131e598b18",
   "metadata": {},
   "source": [
    "As we can see, the humanoid environment gives us a TON of observations! We get dozens of variables representing various positions and velocities of body parts, the center of mass, and a lot of other variables I hardly understand. For an exhaustive list, see the [doc](https://gymnasium.farama.org/environments/mujoco/humanoid/#observation-space). The fact that there are so many variables here is what makes learning latent observations so obvious!\n",
    "\n",
    "We also get some nice summary stats in info, but we aren't going to include them in our scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bc4518-6772-473b-8b89-5984a755ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rollout_data(env_name: str, out_dir: str, n_timesteps: int=10000, print_n_episodes: int=1000):\n",
    "    \"\"\"Simulates `n_timesteps` in the `env_name` environment, saving observations, rewards, and actions to a triplet of .npy files at `out_dir`.\"\"\"\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    obs, info = env.reset()\n",
    "    observations, rewards, actions, done = [], [] , [], []\n",
    "    episode_count = 0\n",
    "\n",
    "    for timestep in range(n_timesteps):  # Run for n_timesteps or until the episode ends\n",
    "        action = env.action_space.sample() #select random action\n",
    "        obs, reward, terminated, truncated, info = env.step(action) #execute and get results\n",
    "        observations.append(obs) #save observation\n",
    "        rewards.append(reward) #save reward\n",
    "        actions.append(action) #save action\n",
    "        done.append(terminated or truncated) #save timestep of each episode's boundary\n",
    "        if terminated or truncated: #check for game over, if so reset env\n",
    "            episode_count+=1\n",
    "            if episode_count % print_n_episodes == 0: print(f\"finished {episode_count} episodes\") #provide update on training\n",
    "            observation, info = env.reset()\n",
    "        env.close()\n",
    "    np_obs, np_rewards, np_actions, np_done = np.array(observations), np.array(rewards), np.array(actions), np.array(done)\n",
    "    print(f\"observations has shape: {np_obs.shape}\\trewards has shape: {np_rewards.shape}\\tactions has shape: {np_actions.shape}\\tdone has shape: {np_done.shape}\")\n",
    "    os.mkdir(f'{out_dir}/{env_name}_{n_timesteps}')\n",
    "    np.save(f'{out_dir}/{env_name}_{n_timesteps}/observations.npy', np_obs) #load with: new_obs = np.load(\"../data/processed/Humanoid-v5_10000_rollout_observations.npy\")\n",
    "    np.save(f'{out_dir}/{env_name}_{n_timesteps}/rewards.npy', np_rewards)\n",
    "    np.save(f'{out_dir}/{env_name}_{n_timesteps}/actions.npy', np_actions)\n",
    "    np.save(f'{out_dir}/{env_name}_{n_timesteps}/done.npy', np_done)\n",
    "    return np_obs, np_rewards, np_actions, np_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c936e8b4-1012-48af-9f9d-a1c0fb0da2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 100 episodes\n",
      "finished 200 episodes\n",
      "finished 300 episodes\n",
      "finished 400 episodes\n",
      "observations has shape: (10000, 348)\trewards has shape: (10000,)\tactions has shape: (10000, 17)\tdone has shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "humanoid_obs, humanoid_rewards, humanoid_actions, humanoid_done = collect_rollout_data('Humanoid-v5', \"../data/processed\", 10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bea542a-9109-4bd2-b80f-8e4775dde9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.88918423, 4.89604958, 4.90176838, ..., 4.90947515, 4.90974383,\n",
       "       4.89052287])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d613d5-e3a6-43f6-abf0-c3cfe81bd712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01211881, -0.12276036, -0.07241314, ...,  0.18449783,\n",
       "        -0.3750561 ,  0.35360506],\n",
       "       [ 0.37878543,  0.04735717,  0.06504802, ..., -0.35926548,\n",
       "         0.0173445 ,  0.0967169 ],\n",
       "       [ 0.21681017, -0.03310588, -0.22394632, ...,  0.13517708,\n",
       "         0.29709256,  0.01220466],\n",
       "       ...,\n",
       "       [-0.11548416,  0.06021108, -0.24303201, ...,  0.29784703,\n",
       "         0.3527969 ,  0.0058307 ],\n",
       "       [-0.23441796,  0.13045473, -0.00081047, ..., -0.21562773,\n",
       "         0.39298594,  0.352991  ],\n",
       "       [ 0.19539085,  0.38917974,  0.3781217 , ..., -0.28425267,\n",
       "         0.3122244 ,  0.16986099]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0536b8fe-b7c4-4b15-9ec7-968f2c8b6845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, ..., False, False, False]), np.int64(407))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_done, humanoid_done.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60900362-cf6f-4514-9708-4fad349d3e9f",
   "metadata": {},
   "source": [
    "## Training the VAE\n",
    "\n",
    "Now that we have an easy function for gathering experiences in the environment, we need to train the VAE module of our world model which will compress the observation space into latent space with fewer dimensions.\n",
    "\n",
    "Note that the original World Model implementation worked with tensorflow 1.18.0. This is incredibly outdated (worked with Python 3.5), so let's get a newer version (tensorflow 2.19.0). Additionally, we need to change the structure of the VAE from working with images to working with a vector of observation data! Luckily, ChatGPT is very good at updating code (or it will be very obvious if it is not!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1389404-530a-43a4-862c-0403f544239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:53:45.742981: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-10 12:53:45.768872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746896025.790914   21466 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746896025.797031   21466 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746896025.811468   21466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746896025.811502   21466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746896025.811508   21466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746896025.811541   21466 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-10 12:53:45.817808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, saving\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "class MLPVAE(Model):\n",
    "    def __init__(self, input_dim=348, z_size=32, kl_tolerance=0.5):\n",
    "        super(MLPVAE, self).__init__()\n",
    "        self.z_size = z_size\n",
    "        self.kl_tolerance = kl_tolerance\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(input_dim,)),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(2 * z_size),  # output both mu and logvar\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(z_size,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(input_dim, activation='linear'),  # output same shape as input\n",
    "        ])\n",
    "\n",
    "    def sample_z(self, mu, logvar):\n",
    "        eps = tf.random.normal(shape=tf.shape(mu))\n",
    "        sigma = tf.exp(0.5 * logvar)\n",
    "        return mu + sigma * eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = tf.split(h, num_or_size_splits=2, axis=1)\n",
    "        logvar = tf.clip_by_value(logvar, -10.0, 10.0)  # helps with exploding values\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def call(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.sample_z(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        x_recon, mu, logvar = self(x)\n",
    "        recon_loss = tf.reduce_mean(tf.reduce_sum(tf.square(x - x_recon), axis=1))\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=1)\n",
    "        kl_loss = tf.maximum(kl_loss, self.kl_tolerance * self.z_size)\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = recon_loss + kl_loss\n",
    "        return total_loss, recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97e9ff-74f4-4a65-b397-11e381a66fb6",
   "metadata": {},
   "source": [
    "Let's also write a training function for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac2fe07-2e6d-4246-a75a-348182aac96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x_train, batch_size=64, shuffle_buffer=10000):\n",
    "    # Assuming x_train is a NumPy array of shape [n_samples, 348]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(x_train.astype(np.float32))\n",
    "    dataset = dataset.shuffle(shuffle_buffer).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def train_vae(model, dataset, epochs=10, learning_rate=1e-4):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_batches = 0\n",
    "        for x_batch in dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss, recon_loss, kl_loss = model.compute_loss(x_batch)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            total_loss += loss.numpy()\n",
    "            total_batches += 1\n",
    "\n",
    "        avg_loss = total_loss / total_batches\n",
    "        print(f\"Epoch {epoch+1}: avg loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0227816c-8f87-4374-860d-49162c0256d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:53:53.952050: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/seansteinle/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "2025-05-10 12:54:14.168318: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg loss = 294404.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:54:34.243369: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg loss = 124580.4062\n",
      "Epoch 3: avg loss = 66752.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:55:23.387848: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg loss = 57464.8281\n",
      "Epoch 5: avg loss = 52356.0273\n",
      "Epoch 6: avg loss = 47033.0430\n",
      "Epoch 7: avg loss = 41048.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:56:45.393300: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg loss = 36293.6836\n",
      "Epoch 9: avg loss = 32545.5039\n",
      "Epoch 10: avg loss = 28815.9082\n",
      "Epoch 11: avg loss = 25161.7969\n",
      "Epoch 12: avg loss = 21866.2051\n",
      "Epoch 13: avg loss = 19387.0508\n",
      "Epoch 14: avg loss = 17487.5430\n",
      "Epoch 15: avg loss = 15973.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 12:59:21.870055: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg loss = 14745.2646\n",
      "Epoch 17: avg loss = 13713.4287\n",
      "Epoch 18: avg loss = 12851.3877\n",
      "Epoch 19: avg loss = 12226.2646\n",
      "Epoch 20: avg loss = 11608.0508\n"
     ]
    }
   ],
   "source": [
    "# x_train should be a NumPy array of shape (n_samples, 348)\n",
    "x_train = humanoid_obs\n",
    "x_train = (x_train - np.mean(x_train, axis=0)) / (np.std(x_train, axis=0) + 1e-6)\n",
    "\n",
    "dataset = create_dataset(humanoid_obs, batch_size=64)\n",
    "vae = MLPVAE(input_dim=348, z_size=32)\n",
    "train_vae(vae, dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4012c-cd27-45fd-bbc7-82e4a1be44cd",
   "metadata": {},
   "source": [
    "Loss is going down! At first I got a tons of NAN values, but it's because I wasn't normalizing the input data and I also needed to clip the logvar values we were getting as a result of the encoding process. If you get NANs again, a lower learning rate could help too. Onto saving the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ae0e21-af4e-4a66-b0a0-8be8d82d5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights('../models/vae/humanoid_10000_vae_model.weights.h5') #save ONLY weights -- much simpler than serializing the entire object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8abe6c45-c5ae-4854-989f-fa2695cbf459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_vae = MLPVAE(input_dim=348, z_size=32) #instantiate new model object \n",
    "new_vae(tf.zeros((1, 348))) #invoke it to build its shape \n",
    "new_vae.load_weights('../models/vae/humanoid_10000_vae_model.weights.h5') #now load weights into empty vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d3e5358-9331-49b2-87c9-bba5693775d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLPVAE name=mlpvae_1, built=True>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "474e51af-98f1-4306-8971-c5d3c8edceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLPVAE name=mlpvae, built=True>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d1e06-9bb3-4ffd-bcdd-1e77bc6db66c",
   "metadata": {},
   "source": [
    "## Training the MDN-RNN\n",
    "\n",
    "Now that we have a model which captures observations, we're theoretically ~1/3 done with the project! I say theoretically because this was probably the easiest part of the project. Now onto the meat of world models: capturing the transitions of our environment and training the MDN-RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9e9b5-64c8-4c11-8d0a-5ca8cdefa295",
   "metadata": {},
   "source": [
    "### Prepping Rollout Data for the MDN-RNN\n",
    "\n",
    "To train the MDN-RNN, we first need to enhance our basic rollout dataset with predictions of `mu` and `logvar` for each experience. Then we'll feed this information to the MDN-RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "960d5f8f-30a5-45e5-b013-48de1be22c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 348), (10000,), (10000, 17), (10000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the dataset records still in memory. Note that we only need the observations for now!\n",
    "humanoid_obs.shape, humanoid_rewards.shape, humanoid_actions.shape, humanoid_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51554a1a-a2db-4db8-8442-2a18e2b27427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLPVAE name=mlpvae, built=True>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also use the VAE still in memory!\n",
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e69fb5c-cda7-4adb-ab82-c2e902e7a80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.39437816e+00,  9.99968250e-01,  3.79864485e-03,  6.59385841e-03,\n",
       "       -2.36428642e-03, -6.44013275e-03,  4.04482542e-02, -1.73932945e-02,\n",
       "        7.02069696e-03, -1.64809519e-02, -5.87085982e-02, -8.31239564e-02,\n",
       "       -2.32992584e-02,  5.96162997e-02, -3.89616689e-02,  2.65256705e-03,\n",
       "       -8.19216933e-03, -1.37551596e-02,  1.69978972e-02, -4.73424357e-03,\n",
       "       -5.79563778e-03,  2.03695153e-02,  2.00603784e-01,  4.37858659e-02,\n",
       "       -2.19800178e-01,  1.58938603e-01,  4.42704435e-02,  1.07000006e+00,\n",
       "       -1.31639174e+00,  2.79643428e+00, -1.52624409e+00,  1.82807029e+00,\n",
       "       -2.23633396e+00, -7.54125526e+00, -1.01836506e+01, -1.99326228e+00,\n",
       "        5.13092967e+00, -4.59377304e+00, -5.50918487e-01, -1.96932012e+00,\n",
       "       -1.40859456e+00,  2.99984654e+00, -1.34652410e-01, -1.24951469e+00,\n",
       "        1.88820864e+00,  2.30075750e+00,  2.28182635e+00,  4.14710432e-02,\n",
       "       -9.92898973e-05,  1.05918959e-02,  7.30889934e-03, -3.23869504e-02,\n",
       "       -1.31595755e-02,  4.35344126e+00,  8.90746237e+00,  9.52378399e-02,\n",
       "        8.98319463e-02,  1.05553218e-02, -3.52709162e-05,  7.73633665e-03,\n",
       "       -4.12081279e-04, -3.98214568e-02,  1.88512814e-03,  4.39470192e-01,\n",
       "        2.26194671e+00,  5.84367644e-02,  4.43126629e-02,  6.61836511e-02,\n",
       "       -9.72208063e-05,  9.21402633e-03,  1.46598308e-04, -3.02882681e-01,\n",
       "        4.24621262e-03,  2.01209197e-01,  6.61619413e+00,  2.71440504e-01,\n",
       "        2.31265668e-01,  5.50210073e-02, -1.19906154e-02, -2.15488537e-02,\n",
       "       -7.98458496e-02, -1.25162551e-01, -4.54335844e-01, -8.52821584e-01,\n",
       "        4.75175093e+00,  9.26203423e-01,  9.06597016e-01,  2.99762712e-02,\n",
       "       -8.94362633e-03, -5.68240310e-02, -1.42153180e-01, -9.74429253e-02,\n",
       "       -2.52827967e-01, -1.54885546e+00,  2.75569617e+00,  1.04387105e+00,\n",
       "        1.03319319e+00,  2.32685539e-02, -8.03403503e-03, -6.64424628e-02,\n",
       "       -1.23929200e-01, -8.72447088e-02, -1.62729775e-01, -1.34579535e+00,\n",
       "        1.76714587e+00,  2.76112935e-01,  2.35178675e-01,  5.66665553e-02,\n",
       "        1.29265828e-02, -2.48024578e-02,  8.23955110e-02, -1.33439850e-01,\n",
       "        4.60690237e-01, -8.62355634e-01,  4.75175093e+00,  9.36262962e-01,\n",
       "        9.13323675e-01,  3.12739685e-02,  8.10098174e-03, -4.76427761e-02,\n",
       "        1.49989004e-01, -8.41867924e-02,  2.65127648e-01, -1.55560507e+00,\n",
       "        2.75569617e+00,  1.05389287e+00,  1.03851761e+00,  2.28267805e-02,\n",
       "        5.45321997e-03, -4.23642100e-02,  1.32944917e-01, -5.54148798e-02,\n",
       "        1.73899775e-01, -1.35096817e+00,  1.76714587e+00,  4.26491874e-01,\n",
       "        3.29090691e-01,  1.26603355e-01,  3.64572805e-02, -4.92210044e-02,\n",
       "        1.76137353e-01,  1.25258134e-01, -4.20252180e-01,  7.16171052e-01,\n",
       "        1.66108048e+00,  3.19365126e-01,  3.43553493e-01,  1.81916706e-01,\n",
       "        8.10530348e-02, -1.56637923e-01,  1.28067384e-01,  3.47613667e-01,\n",
       "       -3.02173579e-01,  5.38561823e-01,  1.22954019e+00,  4.26931500e-01,\n",
       "        3.35676453e-01,  1.23552214e-01, -3.77675891e-02, -5.28779414e-02,\n",
       "       -1.74033075e-01,  1.32919399e-01,  4.11529703e-01,  7.22135015e-01,\n",
       "        1.66108048e+00,  3.19012347e-01,  3.51891158e-01,  1.77710029e-01,\n",
       "       -7.81811371e-02, -1.60450764e-01, -1.23328197e-01,  3.52191595e-01,\n",
       "        2.88100216e-01,  5.45412730e-01,  1.22954019e+00,  1.73509414e-01,\n",
       "        3.29577845e-02,  1.06881399e+00,  1.84553783e-01,  1.24248639e-01,\n",
       "       -2.19626338e-01,  1.92841158e-01,  2.84571770e+00, -2.26589413e-01,\n",
       "       -5.44933608e-01,  1.10626995e-01, -2.60089933e-01, -1.33298722e+00,\n",
       "        2.86230111e+00, -1.56859000e-01, -5.46984423e-01, -8.53191257e-02,\n",
       "       -2.58365234e-01,  1.86648624e-01, -4.70756995e+00, -2.45160691e+00,\n",
       "       -3.89355504e-01, -1.65511101e-01,  1.10556102e-01,  4.63512620e-01,\n",
       "        5.47601473e+00, -2.48834294e+00,  3.61079460e+00, -2.75034507e-01,\n",
       "       -1.02949217e-01,  4.63512620e-01,  5.47601473e+00, -2.48834294e+00,\n",
       "        3.61079460e+00, -2.75034507e-01, -1.02949217e-01,  9.90967188e-02,\n",
       "       -1.67530526e+00, -5.43371401e+00, -1.12680277e+00, -2.42014373e-01,\n",
       "       -2.80978549e-01,  1.38231260e-01, -1.12489554e+00, -5.42782725e+00,\n",
       "       -9.09101435e-01, -2.57277815e-01, -3.01107559e-01,  1.38231260e-01,\n",
       "       -1.12489554e+00, -5.42782725e+00, -9.09101435e-01, -2.57277815e-01,\n",
       "       -3.01107559e-01, -1.44993285e+00,  2.41891476e-01, -7.16733519e-01,\n",
       "        3.83956821e-01, -7.10996021e-01, -4.98661237e-01, -1.44605179e+00,\n",
       "       -1.88213661e+00,  1.40354429e+00,  3.31088952e-01, -1.07363816e+00,\n",
       "       -8.61848032e-01,  4.19381921e-02, -7.89477839e-01,  1.28942707e-01,\n",
       "        4.50187094e-01,  5.64941946e-02, -1.97523345e-01,  1.28511494e-02,\n",
       "       -2.11945321e+00, -1.21088559e+00,  4.29419901e-01,  2.87922766e-01,\n",
       "       -4.26799175e-01, -1.22760363e+01, -1.21188136e+00, -7.24131390e+00,\n",
       "        3.20302337e+01, -1.23790711e+01, -1.24142244e+01, -4.78494674e+01,\n",
       "       -8.56245086e+00,  2.68748313e+01, -8.35249990e+01,  6.73892975e+01,\n",
       "       -8.31130147e+00,  4.10897769e+00,  7.02138692e+00,  4.61244583e+00,\n",
       "       -9.37640220e+00,  8.84012654e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf611482-45e7-49f5-9fe6-378f2665986f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#That's it! Just predict for our entire observation set.\n",
    "mu, logvar = vae.encode(humanoid_obs)\n",
    "humanoid_z = vae.sample_z(mu, logvar).numpy()\n",
    "humanoid_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e0a85a-e3e4-477a-8f2a-bea624a053ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'../data/processed/Humanoid-v5_10000/z.npy', humanoid_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e803dedf-6daa-47ee-ae31-395a0268b595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 348), (10000,), (10000, 17), (10000,), (10000, 32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the dataset records still in memory. Note that we only need the observations for now!\n",
    "humanoid_obs.shape, humanoid_rewards.shape, humanoid_actions.shape, humanoid_done.shape, humanoid_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d4e24-7e60-4ffb-b4f4-bc8a1f79bf06",
   "metadata": {},
   "source": [
    "### Core Training\n",
    "\n",
    "Now that we have our mu and logvar arrays and also episode-wise aggregations of all of our data, we can train our MDN-RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc327863-9607-40da-8f2c-e9d2b5339efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORE MODEL CLASS\n",
    "class MDNRNN(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, action_dim, hidden_dim=256, num_mixtures=5):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.input_dim = latent_dim + action_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_mixtures = num_mixtures\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = layers.LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "        # MDN output: means, stddevs, and mixture weights for latent prediction\n",
    "        self.mdn_dense = layers.Dense(num_mixtures * (2 * latent_dim + 1))\n",
    "\n",
    "        # Predict reward (scalar)\n",
    "        self.reward_dense = layers.Dense(1)\n",
    "\n",
    "        # Predict done (binary classification)\n",
    "        self.done_dense = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, initial_state=None, training=False):\n",
    "        \"\"\"\n",
    "        inputs: (batch, seq_len, latent_dim + action_dim)\n",
    "        \"\"\"\n",
    "        lstm_out, h, c = self.lstm(inputs, initial_state=initial_state, training=training)\n",
    "\n",
    "        mdn_out = self.mdn_dense(lstm_out)\n",
    "        reward_pred = self.reward_dense(lstm_out)\n",
    "        done_pred = self.done_dense(lstm_out)\n",
    "\n",
    "        return mdn_out, reward_pred, done_pred, [h, c]\n",
    "\n",
    "    def get_mdn_params(self, mdn_out):\n",
    "        \"\"\"Split MDN output into pi, mu, sigma.\"\"\"\n",
    "        out = tf.reshape(mdn_out, [-1, self.num_mixtures, 2 * self.latent_dim + 1])\n",
    "        pi = out[:, :, 0]\n",
    "        mu = out[:, :, 1 : 1 + self.latent_dim]\n",
    "        log_sigma = out[:, :, 1 + self.latent_dim :]\n",
    "        sigma = tf.exp(log_sigma)\n",
    "\n",
    "        pi = tf.nn.softmax(pi, axis=-1)  # mixture weights\n",
    "        return pi, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "721e71d3-a274-41dc-85ab-6ede5164807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS IMPLEMENTATION\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "def mdn_loss(z_target, pi, mu, sigma, eps=1e-8):\n",
    "    \"\"\"\n",
    "    z_target: [batch * seq_len, latent_dim]\n",
    "    pi: [batch * seq_len, num_mixtures]\n",
    "    mu: [batch * seq_len, num_mixtures, latent_dim]\n",
    "    sigma: [batch * seq_len, num_mixtures, latent_dim]\n",
    "    \"\"\"\n",
    "    # Expand target for broadcasting: [batch, 1, latent_dim]\n",
    "    z_expanded = tf.expand_dims(z_target, axis=1)\n",
    "\n",
    "    # Create component Gaussians\n",
    "    normal_dist = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    log_probs = normal_dist.log_prob(z_expanded)  # shape: [batch, num_mixtures, latent_dim]\n",
    "\n",
    "    # Sum over latent_dim: total log prob of each mixture component\n",
    "    log_probs = tf.reduce_sum(log_probs, axis=-1)  # shape: [batch, num_mixtures]\n",
    "\n",
    "    # Weight by mixture coefficients\n",
    "    weighted_log_probs = log_probs + tf.math.log(pi + eps)  # log(pi * P)\n",
    "    \n",
    "    # LogSumExp over mixture components to marginalize\n",
    "    log_likelihood = tf.reduce_logsumexp(weighted_log_probs, axis=-1)  # shape: [batch]\n",
    "\n",
    "    # Negative log-likelihood\n",
    "    return -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "def combined_loss(z_target, pi, mu, sigma, reward_target, reward_pred, done_target, done_pred,\n",
    "                  reward_weight=1.0, done_weight=1.0):\n",
    "    loss_mdn = mdn_loss(z_target, pi, mu, sigma)\n",
    "    loss_reward = tf.reduce_mean(tf.square(reward_target - reward_pred))\n",
    "    loss_done = tf.reduce_mean(tf.keras.losses.binary_crossentropy(done_target, done_pred))\n",
    "\n",
    "    return loss_mdn + reward_weight * loss_reward + done_weight * loss_done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fadeb8d4-2d42-406a-bd7f-72f10c866934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING FUNCTION\n",
    "def train_mdnrnn(model, dataset, epochs=10, learning_rate=1e-4, reward_weight=1.0, done_weight=1.0):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_mdn_loss = 0.0\n",
    "        total_reward_loss = 0.0\n",
    "        total_done_loss = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for z_action, (z_next, reward, done) in dataset:\n",
    "            # Flatten z_action into shape (batch, seq_len, latent_dim + action_dim)\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Forward pass through the model\n",
    "                mdn_out, reward_pred, done_pred, _ = model(z_action, training=True)\n",
    "                pi, mu, sigma = model.get_mdn_params(mdn_out)\n",
    "\n",
    "                # Compute MDN, reward, and done losses\n",
    "                loss_mdn = mdn_loss(tf.reshape(z_next, [-1, model.latent_dim]), pi, mu, sigma)\n",
    "                loss_reward = tf.reduce_mean(tf.square(reward - reward_pred))\n",
    "                loss_done = tf.reduce_mean(tf.keras.losses.binary_crossentropy(done, done_pred))\n",
    "\n",
    "                # Total loss\n",
    "                total_loss = loss_mdn + reward_weight * loss_reward + done_weight * loss_done\n",
    "\n",
    "            # Compute gradients and apply\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Accumulate the loss values\n",
    "            total_loss += total_loss.numpy()\n",
    "            total_mdn_loss += loss_mdn.numpy()\n",
    "            total_reward_loss += loss_reward.numpy()\n",
    "            total_done_loss += loss_done.numpy()\n",
    "\n",
    "            total_batches += 1\n",
    "\n",
    "        # Compute and print average losses for the epoch\n",
    "        avg_loss = total_loss / total_batches\n",
    "        avg_mdn_loss = total_mdn_loss / total_batches\n",
    "        avg_reward_loss = total_reward_loss / total_batches\n",
    "        avg_done_loss = total_done_loss / total_batches\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  avg loss = {avg_loss:.4f}, mdn_loss = {avg_mdn_loss:.4f}, \"\n",
    "              f\"reward_loss = {avg_reward_loss:.4f}, done_loss = {avg_done_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc5a999-ce29-4aac-91f2-ef685a39b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA HANDLING\n",
    "def preprocess_data(observations, actions, rewards, dones, sequence_length):\n",
    "    \"\"\"\n",
    "    Yields tuples of the form:\n",
    "    z_action: (sequence_length, latent_dim + action_dim)\n",
    "    targets:  (z_next, reward, done), each of shape (sequence_length, ...)\n",
    "    \"\"\"\n",
    "    for i in range(len(observations) - sequence_length):\n",
    "        z_seq = observations[i:i+sequence_length]\n",
    "        a_seq = actions[i:i+sequence_length]\n",
    "        z_action = np.concatenate([z_seq, a_seq], axis=-1).astype(np.float32)\n",
    "\n",
    "        z_next = observations[i+1:i+sequence_length+1].astype(np.float32)\n",
    "        reward = rewards[i+1:i+sequence_length+1].astype(np.float32)\n",
    "        done = dones[i+1:i+sequence_length+1].astype(np.float32)\n",
    "\n",
    "        yield (\n",
    "            z_action.astype(np.float32),\n",
    "            (\n",
    "                z_next.astype(np.float32),\n",
    "                reward[:, None].astype(np.float32),  # <–– reshape from (T,) to (T,1)\n",
    "                done[:, None].astype(np.float32)     # <–– reshape from (T,) to (T,1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "sequence_length = 10\n",
    "latent_dim = 32\n",
    "action_dim = 17\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: preprocess_data(humanoid_z, humanoid_actions, humanoid_rewards, humanoid_done, sequence_length),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(sequence_length, latent_dim + action_dim), dtype=tf.float32),\n",
    "        (\n",
    "            tf.TensorSpec(shape=(sequence_length, latent_dim), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(sequence_length, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(sequence_length, 1), dtype=tf.float32),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7bc4a56-e063-481c-a146-5f5c40ebf6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:01:26.248475: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 192 of 1000\n",
      "2025-05-10 13:01:32.488861: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  avg loss = 1.6931, mdn_loss = 894.2740, reward_loss = 13.1924, done_loss = 0.3610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:04:03.440020: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 188 of 1000\n",
      "2025-05-10 13:04:10.080250: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  avg loss = 1.3791, mdn_loss = 189.5247, reward_loss = 3.1045, done_loss = 0.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:06:29.482147: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 200 of 1000\n",
      "2025-05-10 13:06:35.321125: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  avg loss = 0.9657, mdn_loss = 157.1093, reward_loss = 2.3987, done_loss = 0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:08:44.712149: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 163 of 1000\n",
      "2025-05-10 13:08:52.979869: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  avg loss = 0.8559, mdn_loss = 145.9258, reward_loss = 2.0311, done_loss = 0.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:11:04.935141: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 218 of 1000\n",
      "2025-05-10 13:11:09.160856: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  avg loss = 0.9553, mdn_loss = 139.0963, reward_loss = 1.7937, done_loss = 0.1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:13:16.326822: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 221 of 1000\n",
      "2025-05-10 13:13:20.527898: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  avg loss = 0.8582, mdn_loss = 134.4886, reward_loss = 1.6422, done_loss = 0.1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:15:34.330901: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 221 of 1000\n",
      "2025-05-10 13:15:38.496574: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  avg loss = 0.8813, mdn_loss = 131.1155, reward_loss = 1.5424, done_loss = 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:18:06.976284: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 190 of 1000\n",
      "2025-05-10 13:18:12.882398: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  avg loss = 0.8353, mdn_loss = 125.5876, reward_loss = 1.4757, done_loss = 0.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:20:50.361600: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 177 of 1000\n",
      "2025-05-10 13:20:57.826262: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  avg loss = 0.8084, mdn_loss = 116.8234, reward_loss = 1.4340, done_loss = 0.1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:23:46.273652: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:8: Filling up shuffle buffer (this may take a while): 163 of 1000\n",
      "2025-05-10 13:23:54.390910: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  avg loss = 0.7236, mdn_loss = 115.2999, reward_loss = 1.3894, done_loss = 0.1717\n"
     ]
    }
   ],
   "source": [
    "mdnrnn = MDNRNN(latent_dim=32, action_dim=17)\n",
    "train_mdnrnn(mdnrnn, train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56356c1c-d3e4-4d41-8f0b-fb7b11e1b9e4",
   "metadata": {},
   "source": [
    "## Training the Controller\n",
    "\n",
    "Now that we have a VAE and an MDN-RNN that are (presumably) learning, let's write the final piece of the puzzle -- the MDN-RNN!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "769deb41-cd7c-40d2-8272-8b134a736d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, saving\n",
    "import gymnasium as gym\n",
    "\n",
    "# --- Controller model ---\n",
    "@saving.register_keras_serializable()\n",
    "class LinearController(Model):\n",
    "    def __init__(self, input_dim, action_dim):\n",
    "        super(LinearController, self).__init__()\n",
    "        self.linear = layers.Dense(action_dim, activation='tanh', use_bias=False)\n",
    "        self.linear(tf.zeros((1, input_dim)))  # force build so weights are initialized\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs)\n",
    "\n",
    "    def get_weights_flat(self):\n",
    "        return tf.reshape(self.linear.kernel, [-1])\n",
    "\n",
    "    def set_weights_flat(self, flat_weights):\n",
    "        new_weights = tf.reshape(flat_weights, self.linear.kernel.shape)\n",
    "        self.linear.kernel.assign(new_weights)\n",
    "\n",
    "# --- Evolution strategy ---\n",
    "def evolve_controller(controller, vae, mdn_rnn, env, generations=10, pop_size=64, sigma=0.1, elite_frac=0.2):\n",
    "    input_dim = controller.linear.kernel.shape[0]\n",
    "    action_dim = controller.linear.kernel.shape[1]\n",
    "    weight_dim = input_dim * action_dim\n",
    "\n",
    "    base_weights = controller.get_weights_flat().numpy()\n",
    "    elite_num = max(1, int(pop_size * elite_frac))\n",
    "\n",
    "    for gen in range(generations):\n",
    "        population = [base_weights + sigma * np.random.randn(weight_dim) for _ in range(pop_size)]\n",
    "        scores = []\n",
    "\n",
    "        for i, individual in enumerate(population):\n",
    "            controller.set_weights_flat(individual)\n",
    "            reward = evaluate_controller(controller, vae, mdn_rnn, env)\n",
    "            scores.append((reward, individual))\n",
    "\n",
    "        scores.sort(key=lambda x: -x[0])\n",
    "        elites = [w for _, w in scores[:elite_num]]\n",
    "        new_mean = np.mean(elites, axis=0)\n",
    "        base_weights = new_mean\n",
    "\n",
    "        print(f\"Gen {gen+1}: Best score = {scores[0][0]:.2f}\")\n",
    "\n",
    "    controller.set_weights_flat(base_weights)\n",
    "    return controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cd63ed3-a963-4d87-a828-052308bc61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_controller(controller, vae, mdn_rnn, env, max_steps=1000):\n",
    "    total_reward = 0\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    h = tf.zeros((1, 256))  # RNN hidden state (adjust as needed)\n",
    "\n",
    "    state = [h, h]  # Initialize state for MDN-RNN (h, c)\n",
    "    for step in range(max_steps):\n",
    "        x = tf.convert_to_tensor(obs[None, :], dtype=tf.float32)\n",
    "        mu, _ = vae.encode(x)\n",
    "        z = mu  # Use the mean (mu) as the latent vector\n",
    "\n",
    "        zh = tf.concat([z, h], axis=1)  # Concatenate latent vector and hidden state\n",
    "        action = controller(zh).numpy()[0]  # Get action from controller\n",
    "\n",
    "        # Step in the environment\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Update hidden state using the MDN-RNN\n",
    "        rnn_input = tf.concat([z, action[None]], axis=1)  # (latent_dim + action_dim)\n",
    "        rnn_input = tf.expand_dims(rnn_input, axis=1)  # Shape becomes (1, 1, 50)\n",
    "\n",
    "        mdn_out, reward_pred, done_pred, state = mdn_rnn(rnn_input, initial_state=state)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        # Optionally: You can use reward_pred and done_pred for monitoring\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90bf92cc-8353-48b2-b544-537e0b8034a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1: Best score = 255.17\n",
      "Gen 2: Best score = 229.66\n",
      "Gen 3: Best score = 255.10\n",
      "Gen 4: Best score = 385.72\n",
      "Gen 5: Best score = 295.82\n",
      "Gen 6: Best score = 375.04\n",
      "Gen 7: Best score = 288.08\n",
      "Gen 8: Best score = 383.42\n",
      "Gen 9: Best score = 489.99\n",
      "Gen 10: Best score = 437.53\n"
     ]
    }
   ],
   "source": [
    "z_dim = 32\n",
    "h_dim = 256\n",
    "action_dim = env.action_space.shape[0]\n",
    "\n",
    "controller = LinearController(input_dim=z_dim + h_dim, action_dim=action_dim)\n",
    "\n",
    "# Assume `vae` and `mdn_rnn` are your pretrained models\n",
    "trained_controller = evolve_controller(controller, vae, mdnrnn, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272fe46e-ff1b-4c45-ace7-27475f681c00",
   "metadata": {},
   "source": [
    "So right now, controller with JUST VAE is working. Also, we're missing the CMA-ES piece! We just do random search optimization right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e1cf1-6112-4fd4-b860-126fcf65018d",
   "metadata": {},
   "source": [
    "## Early Results\n",
    "\n",
    "With a very basic model trained, we can now compare the performance of our model with a random policy and a PPO policy. To do this, we'll have to wrap our model up in a nice interface that plays well with our `play_agent()` function from `./gymnasium_basics.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a99ea422-6d91-42b6-a339-277de71d1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_world_model_policy(vae, mdn_rnn, controller):\n",
    "    h = tf.zeros((1, 256))\n",
    "    state = [h, h]\n",
    "\n",
    "    def policy(obs):\n",
    "        nonlocal state, h\n",
    "        x = tf.convert_to_tensor(obs[None, :], dtype=tf.float32)\n",
    "        mu, _ = vae.encode(x)\n",
    "        z = mu\n",
    "\n",
    "        zh = tf.concat([z, h], axis=1)\n",
    "        action = controller(zh).numpy()[0]\n",
    "\n",
    "        rnn_input = tf.concat([z, action[None]], axis=1)\n",
    "        rnn_input = tf.expand_dims(rnn_input, axis=1)  # shape: (1, 1, 50)\n",
    "        _, _, _, state = mdn_rnn(rnn_input, initial_state=state)\n",
    "        h = state[0]\n",
    "\n",
    "        return action\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00480c34-2e85-46e4-9b26-53720c338ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a slightly updated version of play_agent()\n",
    "def play_agent(env_name, model=None, n_timesteps=50, render_mode=\"human\"):\n",
    "    \"\"\"Plays games using a provided model or random policy.\"\"\"\n",
    "    env = gym.make(env_name, render_mode=render_mode)\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    episode_lengths = []\n",
    "    steps = 0\n",
    "\n",
    "    while steps < n_timesteps:\n",
    "        env.render()\n",
    "        if model is None: #random policy\n",
    "            action = env.action_space.sample()\n",
    "        elif hasattr(model, \"predict\"): #SB3 models use 'predict'\n",
    "            action, _ = model.predict(obs)\n",
    "        else: #our model uses `model(obs)`\n",
    "            action = model(obs)  # assumes model is a callable function\n",
    "\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        steps += 1\n",
    "\n",
    "        if terminated or truncated:\n",
    "            episode_lengths.append(steps)\n",
    "            obs, info = env.reset()\n",
    "\n",
    "    env.close()\n",
    "    return rewards, episode_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6aca399a-014c-4ec9-b085-bfe48d2b424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seansteinle/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/glfw/__init__.py:917: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(3591.5168913059815), np.float64(516.0))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_policy = make_world_model_policy(vae, mdnrnn, trained_controller)\n",
    "rewards, lengths = play_agent(env_name=\"Humanoid-v5\", model=wm_policy, n_timesteps=1000)\n",
    "np.sum(rewards), np.mean(lengths) #avg reward, avg episode length of world model policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02bc9415-0bc7-4468-8aca-f6fbf0d0c166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3591.5168913059815), np.float64(516.0))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(rewards), np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89646d66-98d6-4446-8a98-e4d2fe6a7199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(4653.932537313411), np.float64(510.9))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards, lengths = play_agent(env_name=\"Humanoid-v5\", model=None, n_timesteps=1000)\n",
    "np.sum(rewards), np.mean(lengths) #avg reward, avg episode length of random policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fba6f0-89d1-404e-96d0-bf074e644be6",
   "metadata": {},
   "source": [
    "Okay, world models is still doing worse than random. Tough times! That said, we haven't done the magic of **scaling** yet! Let's break this bad boy up into a few scripts and hit the HPC!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac7c5ea3-5f3b-413f-9ac4-679f9ff84c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnrnn.save_weights('../models/mdnrnn/humanoid_10000_mdnrnn_model.weights.h5') #save ONLY weights -- much simpler than serializing the entire object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0ae7fba-3948-41ab-9cc2-ecbe694720fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mdnrnn = mdnrnn = MDNRNN(latent_dim=32, action_dim=17) #instantiate new model object \n",
    "new_mdnrnn(tf.zeros((1, 10, 49))) #invoke it to build its shape \n",
    "new_mdnrnn.load_weights('../models/mdnrnn/humanoid_10000_mdnrnn_model.weights.h5') #now load weights into empty vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs757-final-project",
   "language": "python",
   "name": "cs757-final-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
