{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bd1649-aa3f-4c0c-a7a2-e9a7d07e76c8",
   "metadata": {},
   "source": [
    "# World Model Core\n",
    "*Sean Steinle, Kiya Aminfar*\n",
    "\n",
    "This notebook walks through the core aspects of world models, developing crucial pieces of code sequentially. Not that this code isn't meant for scale -- instead, this is for a demonstration of how we developed the code that we did.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Collecting Rollout Data](#Collecting-Rollout-Data)\n",
    "2. [Training the VAE](#Training-the-VAE)\n",
    "3. [Training the MDN-RNN](#Training-the-MDN-RNN)\n",
    "    - [Prepping Rollout Data for the MDN-RNN](#Prepping-Rollout-Data-for-the-MDN-RNN)\n",
    "    - [Core Training](#Core-Training)\n",
    "4. [Training the Controller](#Training-the-Controller)\n",
    "5. [Early Results](#Early-Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21544f3f-d6e2-4fda-8b1d-4e6b51e934bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7847949-423a-47be-a72d-62322c9143ee",
   "metadata": {},
   "source": [
    "## Collecting Rollout Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fe9254-55f2-4148-84fc-aa3d9452e7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's begin by creating an instance of our humanoid environment and checking out what basic observations look like.\n",
    "env = gym.make('Humanoid-v5', render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47c4e48-4af5-4ca9-be13-59301b800e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((348,),\n",
       " array([ 1.40602619e+00,  9.90106099e-01,  7.21400582e-03, -4.67594716e-03,\n",
       "         7.54542565e-03,  9.36836000e-03, -8.31537166e-03,  4.05115331e-03,\n",
       "         4.02881107e-04,  7.90516910e-03, -6.83311819e-03, -9.89276723e-03,\n",
       "        -6.14061298e-03, -5.75308330e-03, -9.91729475e-03,  6.02789791e-03,\n",
       "         3.52052936e-05, -4.63146434e-03,  8.84241028e-03, -8.99571457e-03,\n",
       "         9.77278327e-03, -5.49930428e-03, -1.87761082e-03, -4.74033658e-03,\n",
       "        -5.01742490e-03,  8.56199520e-05, -1.80819407e-03,  5.26268603e-03,\n",
       "         5.30459695e-03, -5.30271840e-03, -3.63168874e-03,  8.65317797e-03,\n",
       "        -2.00539408e-04, -7.97576613e-04, -2.13111953e-03, -6.47277394e-03,\n",
       "         5.64883141e-03, -3.62262650e-03, -4.14701912e-03,  2.13638882e-03,\n",
       "         6.35422719e-03, -2.24358261e-03, -5.46226625e-03,  6.86606297e-03,\n",
       "        -6.97945906e-03,  2.30250734e+00,  2.28859078e+00,  4.79432613e-02,\n",
       "        -1.77998742e-03,  1.10994596e-01,  4.11934410e-02, -2.31683185e-01,\n",
       "        -8.09913827e-02,  4.35432911e+00,  8.90746237e+00,  9.51749316e-02,\n",
       "         9.10826784e-02,  1.19657298e-02, -1.82360247e-04,  1.32562523e-02,\n",
       "         2.05459937e-03, -6.82634625e-02, -1.10337881e-02,  4.39181327e-01,\n",
       "         2.26194671e+00,  5.77934828e-02,  4.41708531e-02,  6.67204780e-02,\n",
       "        -7.73770609e-05,  8.86374374e-03, -4.07442412e-05, -3.08348982e-01,\n",
       "        -1.65371996e-02,  1.89913751e-01,  6.61619413e+00,  2.73921389e-01,\n",
       "         2.34352330e-01,  5.09325927e-02, -7.94875588e-03, -1.33191976e-02,\n",
       "        -7.72111467e-02, -8.44909573e-02, -4.41260316e-01, -8.66635001e-01,\n",
       "         4.75175093e+00,  9.30278586e-01,  9.12619968e-01,  2.11664488e-02,\n",
       "        -1.61471281e-03, -1.05997245e-02, -1.24601184e-01, -1.99280640e-02,\n",
       "        -2.21516331e-01, -1.55713802e+00,  2.75569617e+00,  1.04842804e+00,\n",
       "         1.03809582e+00,  1.43347640e-02, -3.70036891e-04, -3.69958457e-03,\n",
       "        -1.03432575e-01, -4.83622529e-03, -1.35210650e-01, -1.35181990e+00,\n",
       "         1.76714587e+00,  2.72571740e-01,  2.29270640e-01,  5.62695995e-02,\n",
       "         1.02208847e-02, -1.62186206e-02,  8.30682436e-02, -1.04158929e-01,\n",
       "         4.65849122e-01, -8.49965369e-01,  4.75175093e+00,  9.30808160e-01,\n",
       "         9.01842391e-01,  3.25437621e-02,  2.01607011e-03, -9.96652021e-03,\n",
       "         1.59896364e-01, -1.99086538e-02,  2.83376436e-01, -1.54757969e+00,\n",
       "         2.75569617e+00,  1.04892488e+00,  1.02832774e+00,  2.45770351e-02,\n",
       "        -1.98218397e-04,  1.39779828e-03,  1.45260563e-01,  1.83593190e-03,\n",
       "         1.90791837e-01, -1.34542760e+00,  1.76714587e+00,  4.29452549e-01,\n",
       "         3.26010867e-01,  1.26921806e-01,  3.06096926e-02, -3.82014854e-02,\n",
       "         1.79420319e-01,  1.00221347e-01, -4.27306484e-01,  7.16053664e-01,\n",
       "         1.66108048e+00,  3.24252935e-01,  3.38956505e-01,  1.71206152e-01,\n",
       "         7.64870716e-02, -1.50451628e-01,  1.28700432e-01,  3.29981181e-01,\n",
       "        -3.00750379e-01,  5.44471175e-01,  1.22954019e+00,  4.26407223e-01,\n",
       "         3.32733888e-01,  1.13342795e-01, -2.58930716e-02, -3.30891294e-02,\n",
       "        -1.71178775e-01,  8.65507649e-02,  4.02933240e-01,  7.26153102e-01,\n",
       "         1.66108048e+00,  3.22916408e-01,  3.38975086e-01,  1.63473518e-01,\n",
       "        -7.22280432e-02, -1.48506913e-01, -1.25870678e-01,  3.23029233e-01,\n",
       "         2.91655895e-01,  5.48463451e-01,  1.22954019e+00,  6.41698961e-05,\n",
       "        -1.88355057e-03,  5.23649504e-03, -1.06684161e-03, -4.58997822e-03,\n",
       "        -4.97327694e-03,  1.24286870e-04, -7.26209913e-03,  1.04638436e-02,\n",
       "         2.96382765e-04, -4.40928896e-03, -4.80303900e-03, -3.50510174e-03,\n",
       "        -7.35032982e-03,  1.03694151e-02,  3.08149894e-04, -4.88086491e-03,\n",
       "        -4.81468819e-03,  5.17378644e-03, -7.93321429e-03,  1.03791244e-02,\n",
       "         2.99824520e-04, -4.98997075e-03, -3.92287602e-03,  5.10412586e-03,\n",
       "        -5.80360310e-03,  1.04187983e-02,  1.13799163e-03, -4.96200684e-03,\n",
       "        -3.95224182e-03,  5.10412586e-03, -5.80360310e-03,  1.04187983e-02,\n",
       "         1.13799163e-03, -4.96200684e-03, -3.95224182e-03,  3.21814262e-03,\n",
       "        -1.06706243e-02,  4.80408032e-03, -2.70747954e-04, -5.09703223e-03,\n",
       "        -5.38506403e-03,  3.09089926e-03, -6.52679374e-03,  4.90529664e-03,\n",
       "         1.36274767e-03, -5.04573683e-03, -5.43157776e-03,  3.09089926e-03,\n",
       "        -6.52679374e-03,  4.90529664e-03,  1.36274767e-03, -5.04573683e-03,\n",
       "        -5.43157776e-03,  1.81373234e-03, -5.55590749e-03,  1.05650207e-02,\n",
       "        -1.43442073e-04, -3.58220916e-03, -4.58192244e-03,  1.80420597e-03,\n",
       "        -3.94653426e-03,  9.00185408e-03, -1.20695967e-04, -3.33191101e-03,\n",
       "        -4.32436420e-03, -4.49254947e-03,  5.13029873e-03,  7.88628748e-03,\n",
       "        -4.26524876e-03, -6.87455128e-03, -4.42628791e-03, -4.57812957e-03,\n",
       "         1.00292864e-02,  1.28567447e-02, -4.20460918e-03, -7.64964250e-03,\n",
       "        -3.66129756e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2035ecfe-44e4-4ab0-b4bb-7213f9d50c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_position': np.float64(-0.0005459767665555986),\n",
       " 'y_position': np.float64(0.0012958979631623128),\n",
       " 'tendon_length': array([ 0.01594519, -0.00305965]),\n",
       " 'tendon_velocity': array([-0.00052439, -0.00133354]),\n",
       " 'distance_from_origin': np.float64(0.00140621554555009)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de32bf7-40c6-40e3-bbd3-b1131e598b18",
   "metadata": {},
   "source": [
    "As we can see, the humanoid environment gives us a TON of observations! We get dozens of variables representing various positions and velocities of body parts, the center of mass, and a lot of other variables I hardly understand. For an exhaustive list, see the [doc](https://gymnasium.farama.org/environments/mujoco/humanoid/#observation-space). The fact that there are so many variables here is what makes learning latent observations so obvious!\n",
    "\n",
    "We also get some nice summary stats in info, but we aren't going to include them in our scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bc4518-6772-473b-8b89-5984a755ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rollout_data(env_name: str, out_dir: str, n_timesteps: int=10000, print_n_episodes: int=1000):\n",
    "    \"\"\"Simulates `n_timesteps` in the `env_name` environment, saving observations, rewards, and actions to a triplet of .npy files at `out_dir`.\"\"\"\n",
    "    env = gym.make(env_name, render_mode='rgb_array')\n",
    "    obs, info = env.reset()\n",
    "    observations, rewards, actions, done = [], [] , [], []\n",
    "    episode_count = 0\n",
    "\n",
    "    for timestep in range(n_timesteps):  # Run for n_timesteps or until the episode ends\n",
    "        action = env.action_space.sample() #select random action\n",
    "        obs, reward, terminated, truncated, info = env.step(action) #execute and get results\n",
    "        observations.append(obs) #save observation\n",
    "        rewards.append(reward) #save reward\n",
    "        actions.append(action) #save action\n",
    "        done.append(terminated or truncated) #save timestep of each episode's boundary\n",
    "        if terminated or truncated: #check for game over, if so reset env\n",
    "            episode_count+=1\n",
    "            if episode_count % print_n_episodes == 0: print(f\"finished {episode_count} episodes\") #provide update on training\n",
    "            observation, info = env.reset()\n",
    "        env.close()\n",
    "    np_obs, np_rewards, np_actions, np_done = np.array(observations), np.array(rewards), np.array(actions), np.array(done)\n",
    "    print(f\"observations has shape: {np_obs.shape}\\trewards has shape: {np_rewards.shape}\\tactions has shape: {np_actions.shape}\\tdone has shape: {np_done.shape}\")\n",
    "    try:\n",
    "        os.mkdir(f'{out_dir}/{env_name}_{n_timesteps}')\n",
    "        np.save(f'{out_dir}/{env_name}_{n_timesteps}/observations.npy', np_obs) #load with: new_obs = np.load(\"../data/processed/Humanoid-v5_10000_rollout_observations.npy\")\n",
    "        np.save(f'{out_dir}/{env_name}_{n_timesteps}/rewards.npy', np_rewards)\n",
    "        np.save(f'{out_dir}/{env_name}_{n_timesteps}/actions.npy', np_actions)\n",
    "        np.save(f'{out_dir}/{env_name}_{n_timesteps}/done.npy', np_done)\n",
    "    except:\n",
    "        print(f\"couldn't save files!\")\n",
    "    return np_obs, np_rewards, np_actions, np_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c936e8b4-1012-48af-9f9d-a1c0fb0da2ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 100 episodes\n",
      "finished 200 episodes\n",
      "finished 300 episodes\n",
      "finished 400 episodes\n",
      "observations has shape: (10000, 348)\trewards has shape: (10000,)\tactions has shape: (10000, 17)\tdone has shape: (10000,)\n",
      "couldn't save files!\n"
     ]
    }
   ],
   "source": [
    "humanoid_obs, humanoid_rewards, humanoid_actions, humanoid_done = collect_rollout_data('Humanoid-v5', \"../data/processed\", 10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bea542a-9109-4bd2-b80f-8e4775dde9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.89430505, 4.88611642, 4.88518135, ..., 4.40739756, 4.67624074,\n",
       "       4.73252955])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d613d5-e3a6-43f6-abf0-c3cfe81bd712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36019275, -0.09605586, -0.18576859, ..., -0.0539204 ,\n",
       "         0.08269034,  0.19883963],\n",
       "       [ 0.32511103, -0.02739318, -0.05949283, ...,  0.07207756,\n",
       "         0.30314222, -0.13952677],\n",
       "       [-0.2139204 , -0.32731584, -0.3209193 , ...,  0.31290817,\n",
       "         0.20741826,  0.25650188],\n",
       "       ...,\n",
       "       [ 0.01935349, -0.37806827, -0.31496435, ..., -0.28754547,\n",
       "        -0.30477956, -0.22121327],\n",
       "       [ 0.1330297 , -0.22771981,  0.33968493, ...,  0.34366018,\n",
       "         0.11724761, -0.19986708],\n",
       "       [ 0.30846435, -0.17688535, -0.25955734, ...,  0.36348575,\n",
       "         0.17780969,  0.09435472]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0536b8fe-b7c4-4b15-9ec7-968f2c8b6845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([False, False, False, ..., False, False, False]), np.int64(423))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_done, humanoid_done.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60900362-cf6f-4514-9708-4fad349d3e9f",
   "metadata": {},
   "source": [
    "## Training the VAE\n",
    "\n",
    "Now that we have an easy function for gathering experiences in the environment, we need to train the VAE module of our world model which will compress the observation space into latent space with fewer dimensions.\n",
    "\n",
    "Note that the original World Model implementation worked with tensorflow 1.18.0. This is incredibly outdated (worked with Python 3.5), so let's get a newer version (tensorflow 2.19.0). Additionally, we need to change the structure of the VAE from working with images to working with a vector of observation data! Luckily, ChatGPT is very good at updating code (or it will be very obvious if it is not!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1389404-530a-43a4-862c-0403f544239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 10:53:58.394557: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-11 10:53:58.410230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746975238.427844   26892 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746975238.432813   26892 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746975238.446158   26892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746975238.446182   26892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746975238.446184   26892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746975238.446185   26892 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-11 10:53:58.451981: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, saving\n",
    "\n",
    "@saving.register_keras_serializable()\n",
    "class MLPVAE(Model):\n",
    "    def __init__(self, input_dim=348, z_size=32, kl_tolerance=0.5):\n",
    "        super(MLPVAE, self).__init__()\n",
    "        self.z_size = z_size\n",
    "        self.kl_tolerance = kl_tolerance\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(input_dim,)),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(2 * z_size),  # output both mu and logvar\n",
    "        ])\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.InputLayer(input_shape=(z_size,)),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dense(input_dim, activation='linear'),  # output same shape as input\n",
    "        ])\n",
    "\n",
    "    def sample_z(self, mu, logvar):\n",
    "        eps = tf.random.normal(shape=tf.shape(mu))\n",
    "        sigma = tf.exp(0.5 * logvar)\n",
    "        return mu + sigma * eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = tf.split(h, num_or_size_splits=2, axis=1)\n",
    "        logvar = tf.clip_by_value(logvar, -10.0, 10.0)  # helps with exploding values\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def call(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.sample_z(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        x_recon, mu, logvar = self(x)\n",
    "        recon_loss = tf.reduce_mean(tf.reduce_sum(tf.square(x - x_recon), axis=1))\n",
    "        kl_loss = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar), axis=1)\n",
    "        kl_loss = tf.maximum(kl_loss, self.kl_tolerance * self.z_size)\n",
    "        kl_loss = tf.reduce_mean(kl_loss)\n",
    "        total_loss = recon_loss + kl_loss\n",
    "        return total_loss, recon_loss, kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97e9ff-74f4-4a65-b397-11e381a66fb6",
   "metadata": {},
   "source": [
    "Let's also write a training function for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac2fe07-2e6d-4246-a75a-348182aac96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(x_train, batch_size=64, shuffle_buffer=10000):\n",
    "    # Assuming x_train is a NumPy array of shape [n_samples, 348]\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(x_train.astype(np.float32))\n",
    "    dataset = dataset.shuffle(shuffle_buffer).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def train_vae(model, dataset, epochs=10, learning_rate=1e-4):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_batches = 0\n",
    "        for x_batch in dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                loss, recon_loss, kl_loss = model.compute_loss(x_batch)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            total_loss += loss.numpy()\n",
    "            total_batches += 1\n",
    "\n",
    "        avg_loss = total_loss / total_batches\n",
    "        print(f\"Epoch {epoch+1}: avg loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0227816c-8f87-4374-860d-49162c0256d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg loss = 306568.8125\n"
     ]
    }
   ],
   "source": [
    "# x_train should be a NumPy array of shape (n_samples, 348)\n",
    "x_train = humanoid_obs\n",
    "x_train = (x_train - np.mean(x_train, axis=0)) / (np.std(x_train, axis=0) + 1e-6)\n",
    "\n",
    "dataset = create_dataset(humanoid_obs, batch_size=64)\n",
    "vae = MLPVAE(input_dim=348, z_size=32)\n",
    "train_vae(vae, dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4012c-cd27-45fd-bbc7-82e4a1be44cd",
   "metadata": {},
   "source": [
    "Loss is going down! At first I got a tons of NAN values, but it's because I wasn't normalizing the input data and I also needed to clip the logvar values we were getting as a result of the encoding process. If you get NANs again, a lower learning rate could help too. Onto saving the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1ae0e21-af4e-4a66-b0a0-8be8d82d5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights('../models/vae/humanoid_10000_vae_model.weights.h5') #save ONLY weights -- much simpler than serializing the entire object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8abe6c45-c5ae-4854-989f-fa2695cbf459",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_vae = MLPVAE(input_dim=348, z_size=32) #instantiate new model object \n",
    "new_vae(tf.zeros((1, 348))) #invoke it to build its shape \n",
    "new_vae.load_weights('../models/vae/humanoid_10000_vae_model.weights.h5') #now load weights into empty vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d3e5358-9331-49b2-87c9-bba5693775d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLPVAE name=mlpvae_2, built=True>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474e51af-98f1-4306-8971-c5d3c8edceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLPVAE name=mlpvae_1, built=True>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d1e06-9bb3-4ffd-bcdd-1e77bc6db66c",
   "metadata": {},
   "source": [
    "## Training the MDN-RNN\n",
    "\n",
    "Now that we have a model which captures observations, we're theoretically ~1/3 done with the project! I say theoretically because this was probably the easiest part of the project. Now onto the meat of world models: capturing the transitions of our environment and training the MDN-RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9e9b5-64c8-4c11-8d0a-5ca8cdefa295",
   "metadata": {},
   "source": [
    "### Prepping Rollout Data for the MDN-RNN\n",
    "\n",
    "To train the MDN-RNN, we first need to enhance our basic rollout dataset with predictions of `mu` and `logvar` for each experience. Then we'll feed this information to the MDN-RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "960d5f8f-30a5-45e5-b013-48de1be22c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 348), (10000,), (10000, 17), (10000,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the dataset records still in memory. Note that we only need the observations for now!\n",
    "humanoid_obs.shape, humanoid_rewards.shape, humanoid_actions.shape, humanoid_done.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51554a1a-a2db-4db8-8442-2a18e2b27427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLPVAE name=mlpvae_1, built=True>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can also use the VAE still in memory!\n",
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e69fb5c-cda7-4adb-ab82-c2e902e7a80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38886569e+00,  9.99897978e-01, -3.86473454e-03, -1.37366724e-02,\n",
       "        6.33536879e-04,  4.72869318e-03,  1.23726442e-01, -2.71861447e-02,\n",
       "        1.90465276e-02, -3.42330410e-02, -1.58563616e-01, -1.29209048e-01,\n",
       "       -2.46233564e-02,  4.49637519e-02, -1.58103099e-01, -1.09594646e-01,\n",
       "        2.24837397e-02, -2.31870835e-02,  8.42925457e-03, -3.01925045e-02,\n",
       "        2.37384980e-02,  2.42204090e-02,  3.73407888e-01,  2.99910596e-02,\n",
       "       -3.61643667e-01,  3.86360986e-01, -3.00772425e+00,  2.65944794e-01,\n",
       "       -6.64950148e-01,  1.12069123e+01, -2.56462351e+00,  3.19647750e+00,\n",
       "       -2.39332040e+00, -1.57812598e+01, -1.39240095e+01, -3.36641598e+00,\n",
       "        3.38142258e+00, -1.56526288e+01, -1.26775093e+01,  1.35818218e+00,\n",
       "       -2.73749089e+00,  8.54538295e-01, -1.72602532e+00,  2.20293519e+00,\n",
       "        1.85266074e+00,  2.29332593e+00,  2.27452413e+00,  4.26554563e-02,\n",
       "        7.56150550e-04,  4.57639885e-02, -3.49123619e-02, -9.35642063e-02,\n",
       "        6.97772305e-02,  4.34507819e+00,  8.90746237e+00,  9.44374101e-02,\n",
       "        8.89875279e-02,  1.06462879e-02,  2.58850016e-04,  7.82803304e-03,\n",
       "       -2.35838370e-03, -4.04985975e-02,  1.24503185e-02,  4.37230838e-01,\n",
       "        2.26194671e+00,  5.86132238e-02,  4.92204049e-02,  7.08710764e-02,\n",
       "        6.86598899e-04,  1.07979121e-02,  7.13012076e-04, -3.50575730e-01,\n",
       "        8.58975273e-03,  2.03934923e-01,  6.61619413e+00,  2.69430121e-01,\n",
       "        2.26314375e-01,  5.73458164e-02, -1.11266065e-02, -1.51863502e-02,\n",
       "       -8.22413717e-02, -1.12540342e-01, -4.68096052e-01, -8.40592361e-01,\n",
       "        4.75175093e+00,  9.21997747e-01,  8.94978908e-01,  3.23164214e-02,\n",
       "       -5.19953488e-03, -3.03663630e-02, -1.55992821e-01, -5.12261923e-02,\n",
       "       -2.78092332e-01, -1.54072466e+00,  2.75569617e+00,  1.04052645e+00,\n",
       "        1.02289687e+00,  2.48595218e-02, -5.59723393e-03, -4.06825210e-02,\n",
       "       -1.39962607e-01, -5.36192636e-02, -1.84469688e-01, -1.34078583e+00,\n",
       "        1.76714587e+00,  2.75301432e-01,  2.38388123e-01,  5.20736053e-02,\n",
       "        1.14766980e-02, -1.79405713e-02,  7.72553155e-02, -1.22415467e-01,\n",
       "        4.37254029e-01, -8.73102076e-01,  4.75175093e+00,  9.33459339e-01,\n",
       "        9.16209822e-01,  2.22928581e-02,  3.98464758e-03, -2.90436935e-02,\n",
       "        1.26272579e-01, -4.92544377e-02,  2.23773987e-01, -1.55965558e+00,\n",
       "        2.75569617e+00,  1.05124705e+00,  1.04149821e+00,  1.60800068e-02,\n",
       "        3.58696403e-03, -3.49334033e-02,  1.06411927e-01, -4.56168199e-02,\n",
       "        1.38955076e-01, -1.35328196e+00,  1.76714587e+00,  4.20611773e-01,\n",
       "        3.32119207e-01,  1.16305243e-01,  3.34117123e-02, -4.64309747e-02,\n",
       "        1.69182328e-01,  1.18316753e-01, -4.01260512e-01,  7.20605485e-01,\n",
       "        1.66108048e+00,  3.18893093e-01,  3.48509804e-01,  1.71774351e-01,\n",
       "        7.56805564e-02, -1.57209925e-01,  1.22745258e-01,  3.43753787e-01,\n",
       "       -2.85963435e-01,  5.46601135e-01,  1.22954019e+00,  4.25779014e-01,\n",
       "        3.25558195e-01,  1.27676120e-01, -3.47025594e-02, -4.53258924e-02,\n",
       "       -1.77475314e-01,  1.17262797e-01,  4.24920396e-01,  7.12923278e-01,\n",
       "        1.66108048e+00,  3.22529676e-01,  3.42226554e-01,  1.77161771e-01,\n",
       "       -7.94115369e-02, -1.54231485e-01, -1.28683755e-01,  3.39977719e-01,\n",
       "        3.02161228e-01,  5.41768613e-01,  1.22954019e+00,  3.82894599e-01,\n",
       "       -3.01287572e+00,  3.00190207e-01,  1.74188040e+00,  2.05667329e-01,\n",
       "       -3.43358082e-01,  3.37654282e-01,  8.21019841e+00, -4.51257117e-01,\n",
       "       -1.15844944e+00,  1.85034030e-01, -4.76909962e-01, -2.21838861e+00,\n",
       "        8.19694222e+00, -2.25281087e-01, -1.15562466e+00, -1.38217643e-01,\n",
       "       -4.63921128e-01,  3.21895940e-01, -7.61917403e+00, -2.59798477e+00,\n",
       "       -1.03333069e+00, -2.41494691e-01,  3.55440898e-01,  7.04661191e-01,\n",
       "        6.30762899e+00, -2.86281718e+00,  4.41605691e+00, -3.92830320e-01,\n",
       "        2.73180299e-01,  7.04661191e-01,  6.30762899e+00, -2.86281718e+00,\n",
       "        4.41605691e+00, -3.92830320e-01,  2.73180299e-01,  2.32553507e-01,\n",
       "       -7.48459801e+00, -3.67722566e+00, -1.72402978e+00, -3.02272698e-01,\n",
       "       -1.22227375e-01,  7.22671391e-01,  5.19519702e+00, -3.85988411e+00,\n",
       "        3.28349993e+00, -4.98451780e-01, -3.04155339e-01,  7.22671391e-01,\n",
       "        5.19519702e+00, -3.85988411e+00,  3.28349993e+00, -4.98451780e-01,\n",
       "       -3.04155339e-01,  1.49355061e+00, -4.90075416e-01, -1.03744305e+00,\n",
       "        6.60504085e-01,  7.65796886e-01, -1.84825901e-01,  1.48906406e+00,\n",
       "       -1.10182253e+00, -4.38430377e-01,  6.59875578e-01,  6.61965189e-01,\n",
       "       -2.90869670e-01, -1.01740133e+00, -7.01643867e-01,  1.06006112e+00,\n",
       "        6.94082456e-01, -5.04387352e-01, -1.14537895e-01, -1.01305092e+00,\n",
       "       -2.05386304e+00, -2.07745296e-01,  6.87095289e-01, -2.87558750e-01,\n",
       "       -3.45827298e-01, -9.60558578e+00,  3.60192746e+01, -1.85768589e+01,\n",
       "        3.66277754e+01, -1.35395542e+01, -9.09341723e+01, -4.03160036e+01,\n",
       "       -2.00877219e+01,  1.75292164e+01, -1.18664530e+02, -2.22426504e+01,\n",
       "        8.75327513e+00, -6.77719191e+00, -1.73498318e+00, -1.34800989e+00,\n",
       "        2.06725858e+00,  4.97099087e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanoid_obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf611482-45e7-49f5-9fe6-378f2665986f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#That's it! Just predict for our entire observation set.\n",
    "mu, logvar = vae.encode(humanoid_obs)\n",
    "humanoid_z = vae.sample_z(mu, logvar).numpy()\n",
    "humanoid_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3e0a85a-e3e4-477a-8f2a-bea624a053ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'../data/processed/Humanoid-v5_10000/z.npy', humanoid_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e803dedf-6daa-47ee-ae31-395a0268b595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 348), (10000,), (10000, 17), (10000,), (10000, 32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the dataset records still in memory. Note that we only need the observations for now!\n",
    "humanoid_obs.shape, humanoid_rewards.shape, humanoid_actions.shape, humanoid_done.shape, humanoid_z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d4e24-7e60-4ffb-b4f4-bc8a1f79bf06",
   "metadata": {},
   "source": [
    "### Core Training\n",
    "\n",
    "Now that we have our mu and logvar arrays and also episode-wise aggregations of all of our data, we can train our MDN-RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc327863-9607-40da-8f2c-e9d2b5339efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORE MODEL CLASS\n",
    "class MDNRNN(tf.keras.Model):\n",
    "    def __init__(self, latent_dim, action_dim, hidden_dim=256, num_mixtures=5):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.input_dim = latent_dim + action_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_mixtures = num_mixtures\n",
    "\n",
    "        # LSTM\n",
    "        self.lstm = layers.LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "        # MDN output: means, stddevs, and mixture weights for latent prediction\n",
    "        self.mdn_dense = layers.Dense(num_mixtures * (2 * latent_dim + 1))\n",
    "\n",
    "        # Predict reward (scalar)\n",
    "        self.reward_dense = layers.Dense(1)\n",
    "\n",
    "        # Predict done (binary classification)\n",
    "        self.done_dense = layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, inputs, initial_state=None, training=False):\n",
    "        \"\"\"\n",
    "        inputs: (batch, seq_len, latent_dim + action_dim)\n",
    "        \"\"\"\n",
    "        lstm_out, h, c = self.lstm(inputs, initial_state=initial_state, training=training)\n",
    "\n",
    "        mdn_out = self.mdn_dense(lstm_out)\n",
    "        reward_pred = self.reward_dense(lstm_out)\n",
    "        done_pred = self.done_dense(lstm_out)\n",
    "\n",
    "        return mdn_out, reward_pred, done_pred, [h, c]\n",
    "\n",
    "    def get_mdn_params(self, mdn_out):\n",
    "        \"\"\"Split MDN output into pi, mu, sigma.\"\"\"\n",
    "        out = tf.reshape(mdn_out, [-1, self.num_mixtures, 2 * self.latent_dim + 1])\n",
    "        pi = out[:, :, 0]\n",
    "        mu = out[:, :, 1 : 1 + self.latent_dim]\n",
    "        log_sigma = out[:, :, 1 + self.latent_dim :]\n",
    "        sigma = tf.exp(log_sigma)\n",
    "\n",
    "        pi = tf.nn.softmax(pi, axis=-1)  # mixture weights\n",
    "        return pi, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "721e71d3-a274-41dc-85ab-6ede5164807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS IMPLEMENTATION\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "def mdn_loss(z_target, pi, mu, sigma, eps=1e-8):\n",
    "    \"\"\"\n",
    "    z_target: [batch * seq_len, latent_dim]\n",
    "    pi: [batch * seq_len, num_mixtures]\n",
    "    mu: [batch * seq_len, num_mixtures, latent_dim]\n",
    "    sigma: [batch * seq_len, num_mixtures, latent_dim]\n",
    "    \"\"\"\n",
    "    # Expand target for broadcasting: [batch, 1, latent_dim]\n",
    "    z_expanded = tf.expand_dims(z_target, axis=1)\n",
    "\n",
    "    # Create component Gaussians\n",
    "    normal_dist = tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    log_probs = normal_dist.log_prob(z_expanded)  # shape: [batch, num_mixtures, latent_dim]\n",
    "\n",
    "    # Sum over latent_dim: total log prob of each mixture component\n",
    "    log_probs = tf.reduce_sum(log_probs, axis=-1)  # shape: [batch, num_mixtures]\n",
    "\n",
    "    # Weight by mixture coefficients\n",
    "    weighted_log_probs = log_probs + tf.math.log(pi + eps)  # log(pi * P)\n",
    "    \n",
    "    # LogSumExp over mixture components to marginalize\n",
    "    log_likelihood = tf.reduce_logsumexp(weighted_log_probs, axis=-1)  # shape: [batch]\n",
    "\n",
    "    # Negative log-likelihood\n",
    "    return -tf.reduce_mean(log_likelihood)\n",
    "\n",
    "def combined_loss(z_target, pi, mu, sigma, reward_target, reward_pred, done_target, done_pred,\n",
    "                  reward_weight=1.0, done_weight=1.0):\n",
    "    loss_mdn = mdn_loss(z_target, pi, mu, sigma)\n",
    "    loss_reward = tf.reduce_mean(tf.square(reward_target - reward_pred))\n",
    "    loss_done = tf.reduce_mean(tf.keras.losses.binary_crossentropy(done_target, done_pred))\n",
    "\n",
    "    return loss_mdn + reward_weight * loss_reward + done_weight * loss_done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fadeb8d4-2d42-406a-bd7f-72f10c866934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING FUNCTION\n",
    "def train_mdnrnn(model, dataset, epochs=10, learning_rate=1e-4, reward_weight=1.0, done_weight=1.0):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        total_mdn_loss = 0.0\n",
    "        total_reward_loss = 0.0\n",
    "        total_done_loss = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        for z_action, (z_next, reward, done) in dataset:\n",
    "            # Flatten z_action into shape (batch, seq_len, latent_dim + action_dim)\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Forward pass through the model\n",
    "                mdn_out, reward_pred, done_pred, _ = model(z_action, training=True)\n",
    "                pi, mu, sigma = model.get_mdn_params(mdn_out)\n",
    "\n",
    "                # Compute MDN, reward, and done losses\n",
    "                loss_mdn = mdn_loss(tf.reshape(z_next, [-1, model.latent_dim]), pi, mu, sigma)\n",
    "                loss_reward = tf.reduce_mean(tf.square(reward - reward_pred))\n",
    "                loss_done = tf.reduce_mean(tf.keras.losses.binary_crossentropy(done, done_pred))\n",
    "\n",
    "                # Total loss\n",
    "                total_loss = loss_mdn + reward_weight * loss_reward + done_weight * loss_done\n",
    "\n",
    "            # Compute gradients and apply\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Accumulate the loss values\n",
    "            total_loss += total_loss.numpy()\n",
    "            total_mdn_loss += loss_mdn.numpy()\n",
    "            total_reward_loss += loss_reward.numpy()\n",
    "            total_done_loss += loss_done.numpy()\n",
    "\n",
    "            total_batches += 1\n",
    "\n",
    "        # Compute and print average losses for the epoch\n",
    "        avg_loss = total_loss / total_batches\n",
    "        avg_mdn_loss = total_mdn_loss / total_batches\n",
    "        avg_reward_loss = total_reward_loss / total_batches\n",
    "        avg_done_loss = total_done_loss / total_batches\n",
    "\n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  avg loss = {avg_loss:.4f}, mdn_loss = {avg_mdn_loss:.4f}, \"\n",
    "              f\"reward_loss = {avg_reward_loss:.4f}, done_loss = {avg_done_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bc5a999-ce29-4aac-91f2-ef685a39b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA HANDLING\n",
    "def preprocess_data(observations, actions, rewards, dones, sequence_length):\n",
    "    \"\"\"\n",
    "    Yields tuples of the form:\n",
    "    z_action: (sequence_length, latent_dim + action_dim)\n",
    "    targets:  (z_next, reward, done), each of shape (sequence_length, ...)\n",
    "    \"\"\"\n",
    "    for i in range(len(observations) - sequence_length):\n",
    "        z_seq = observations[i:i+sequence_length]\n",
    "        a_seq = actions[i:i+sequence_length]\n",
    "        z_action = np.concatenate([z_seq, a_seq], axis=-1).astype(np.float32)\n",
    "\n",
    "        z_next = observations[i+1:i+sequence_length+1].astype(np.float32)\n",
    "        reward = rewards[i+1:i+sequence_length+1].astype(np.float32)\n",
    "        done = dones[i+1:i+sequence_length+1].astype(np.float32)\n",
    "\n",
    "        yield (\n",
    "            z_action.astype(np.float32),\n",
    "            (\n",
    "                z_next.astype(np.float32),\n",
    "                reward[:, None].astype(np.float32),  # <–– reshape from (T,) to (T,1)\n",
    "                done[:, None].astype(np.float32)     # <–– reshape from (T,) to (T,1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "sequence_length = 10\n",
    "latent_dim = 32\n",
    "action_dim = 17\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: preprocess_data(humanoid_z, humanoid_actions, humanoid_rewards, humanoid_done, sequence_length),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(sequence_length, latent_dim + action_dim), dtype=tf.float32),\n",
    "        (\n",
    "            tf.TensorSpec(shape=(sequence_length, latent_dim), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(sequence_length, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(sequence_length, 1), dtype=tf.float32),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7bc4a56-e063-481c-a146-5f5c40ebf6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 10:55:29.717311: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:13: Filling up shuffle buffer (this may take a while): 230 of 1000\n",
      "2025-05-11 10:55:33.254045: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  avg loss = 8.1963, mdn_loss = 4989.6450, reward_loss = 19.1286, done_loss = 0.4089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 10:56:57.988420: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "mdnrnn = MDNRNN(latent_dim=32, action_dim=17)\n",
    "train_mdnrnn(mdnrnn, train_dataset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56356c1c-d3e4-4d41-8f0b-fb7b11e1b9e4",
   "metadata": {},
   "source": [
    "## Training the Controller\n",
    "\n",
    "Now that we have a VAE and an MDN-RNN that are (presumably) learning, let's write the final piece of the puzzle -- the MDN-RNN!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "769deb41-cd7c-40d2-8272-8b134a736d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, saving\n",
    "import gymnasium as gym\n",
    "\n",
    "# --- Controller model ---\n",
    "@saving.register_keras_serializable()\n",
    "class LinearController(Model):\n",
    "    def __init__(self, input_dim, action_dim):\n",
    "        super(LinearController, self).__init__()\n",
    "        self.linear = layers.Dense(action_dim, activation='tanh', use_bias=False)\n",
    "        self.linear(tf.zeros((1, input_dim)))  # force build so weights are initialized\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.linear(inputs)\n",
    "\n",
    "    def get_weights_flat(self):\n",
    "        return tf.reshape(self.linear.kernel, [-1])\n",
    "\n",
    "    def set_weights_flat(self, flat_weights):\n",
    "        new_weights = tf.reshape(flat_weights, self.linear.kernel.shape)\n",
    "        self.linear.kernel.assign(new_weights)\n",
    "\n",
    "# --- Evolution strategy ---\n",
    "def evolve_controller(controller, vae, mdn_rnn, env, generations=10, pop_size=64, sigma=0.1, elite_frac=0.2):\n",
    "    input_dim = controller.linear.kernel.shape[0]\n",
    "    action_dim = controller.linear.kernel.shape[1]\n",
    "    weight_dim = input_dim * action_dim\n",
    "\n",
    "    base_weights = controller.get_weights_flat().numpy()\n",
    "    elite_num = max(1, int(pop_size * elite_frac))\n",
    "\n",
    "    for gen in range(generations):\n",
    "        population = [base_weights + sigma * np.random.randn(weight_dim) for _ in range(pop_size)]\n",
    "        scores = []\n",
    "\n",
    "        for i, individual in enumerate(population):\n",
    "            controller.set_weights_flat(individual)\n",
    "            reward = evaluate_controller(controller, vae, mdn_rnn, env)\n",
    "            scores.append((reward, individual))\n",
    "\n",
    "        scores.sort(key=lambda x: -x[0])\n",
    "        elites = [w for _, w in scores[:elite_num]]\n",
    "        new_mean = np.mean(elites, axis=0)\n",
    "        base_weights = new_mean\n",
    "\n",
    "        print(f\"Gen {gen+1}: Best score = {scores[0][0]:.2f}\")\n",
    "\n",
    "    controller.set_weights_flat(base_weights)\n",
    "    return controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cd63ed3-a963-4d87-a828-052308bc61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_controller(controller, vae, mdn_rnn, env, max_steps=1000):\n",
    "    total_reward = 0\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    h = tf.zeros((1, 256))  # RNN hidden state (adjust as needed)\n",
    "\n",
    "    state = [h, h]  # Initialize state for MDN-RNN (h, c)\n",
    "    for step in range(max_steps):\n",
    "        x = tf.convert_to_tensor(obs[None, :], dtype=tf.float32)\n",
    "        mu, _ = vae.encode(x)\n",
    "        z = mu  # Use the mean (mu) as the latent vector\n",
    "\n",
    "        zh = tf.concat([z, h], axis=1)  # Concatenate latent vector and hidden state\n",
    "        action = controller(zh).numpy()[0]  # Get action from controller\n",
    "\n",
    "        # Step in the environment\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Update hidden state using the MDN-RNN\n",
    "        rnn_input = tf.concat([z, action[None]], axis=1)  # (latent_dim + action_dim)\n",
    "        rnn_input = tf.expand_dims(rnn_input, axis=1)  # Shape becomes (1, 1, 50)\n",
    "\n",
    "        mdn_out, reward_pred, done_pred, state = mdn_rnn(rnn_input, initial_state=state)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        # Optionally: You can use reward_pred and done_pred for monitoring\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90bf92cc-8353-48b2-b544-537e0b8034a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1: Best score = 155.66\n"
     ]
    }
   ],
   "source": [
    "z_dim = 32\n",
    "h_dim = 256\n",
    "action_dim = env.action_space.shape[0]\n",
    "\n",
    "controller = LinearController(input_dim=z_dim + h_dim, action_dim=action_dim)\n",
    "\n",
    "# Assume `vae` and `mdn_rnn` are your pretrained models\n",
    "trained_controller = evolve_controller(controller, vae, mdnrnn, env, generations=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272fe46e-ff1b-4c45-ace7-27475f681c00",
   "metadata": {},
   "source": [
    "So now the controller is working. Also, we're missing the CMA-ES piece! We just do random search optimization right now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e1cf1-6112-4fd4-b860-126fcf65018d",
   "metadata": {},
   "source": [
    "## Early Results\n",
    "\n",
    "With a very basic model trained, we can now compare the performance of our model with a random policy and a PPO policy. To do this, we'll have to wrap our model up in a nice interface that plays well with our `play_agent()` function from `./gymnasium_basics.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a99ea422-6d91-42b6-a339-277de71d1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_world_model_policy(vae, mdn_rnn, controller):\n",
    "    h = tf.zeros((1, 256))\n",
    "    state = [h, h]\n",
    "\n",
    "    def policy(obs):\n",
    "        nonlocal state, h\n",
    "        x = tf.convert_to_tensor(obs[None, :], dtype=tf.float32)\n",
    "        mu, _ = vae.encode(x)\n",
    "        z = mu\n",
    "\n",
    "        zh = tf.concat([z, h], axis=1)\n",
    "        action = controller(zh).numpy()[0]\n",
    "\n",
    "        rnn_input = tf.concat([z, action[None]], axis=1)\n",
    "        rnn_input = tf.expand_dims(rnn_input, axis=1)  # shape: (1, 1, 50)\n",
    "        _, _, _, state = mdn_rnn(rnn_input, initial_state=state)\n",
    "        h = state[0]\n",
    "\n",
    "        return action\n",
    "\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00480c34-2e85-46e4-9b26-53720c338ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a slightly updated version of play_agent()\n",
    "def play_agent(env_name, model=None, n_timesteps=50, render_mode=\"human\"):\n",
    "    \"\"\"Plays games using a provided model or random policy.\"\"\"\n",
    "    env = gym.make(env_name, render_mode=render_mode)\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    episode_lengths = []\n",
    "    steps = 0\n",
    "\n",
    "    while steps < n_timesteps:\n",
    "        env.render()\n",
    "        if model is None: #random policy\n",
    "            action = env.action_space.sample()\n",
    "        elif hasattr(model, \"predict\"): #SB3 models use 'predict'\n",
    "            action, _ = model.predict(obs)\n",
    "        else: #our model uses `model(obs)`\n",
    "            action = model(obs)  # assumes model is a callable function\n",
    "\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        steps += 1\n",
    "\n",
    "        if terminated or truncated:\n",
    "            episode_lengths.append(steps)\n",
    "            obs, info = env.reset()\n",
    "\n",
    "    env.close()\n",
    "    return rewards, episode_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6aca399a-014c-4ec9-b085-bfe48d2b424a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26892/834653123.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwm_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_world_model_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdnrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_controller\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Humanoid-v5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwm_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#avg reward, avg episode length of world model policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26892/1623317578.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(env_name, model, n_timesteps, render_mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#SB3 models use 'predict'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#our model uses `model(obs)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# assumes model is a callable function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26892/1214779073.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(obs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape: (1, 1, 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdn_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0;34m\"layers will not see the mask.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 )\n\u001b[1;32m    947\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0;31m# Destroy call context if we created it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m                 \u001b[0mcall_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_26892/708424990.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, inputs, initial_state, training)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[1;32m     25\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmdn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmdn_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mreward_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0;34m\"layers will not see the mask.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 )\n\u001b[1;32m    947\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0;31m# Destroy call context if we created it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_reset_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[1;32m     55\u001b[0m                 \u001b[0mcall_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mobject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}.call()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Plain flow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mnew_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mnew_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mbound_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/rnn/lstm.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         return super().call(\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    404\u001b[0m         self._maybe_config_dropout_masks(\n\u001b[1;32m    405\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         )\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         last_output, outputs, states = self.inner_loop(\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0msequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/rnn/lstm.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;34m\"but cuDNN is not supported for this layer configuration \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;34m\"with this backend. Pass use_cudnn='auto' to fallback \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0;34m\"to a non-cuDNN implementation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             )\n\u001b[0;32m--> 579\u001b[0;31m         return super().inner_loop(\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         return backend.rnn(\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/keras/src/backend/tensorflow/rnn.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mmax_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_steps_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mmax_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         while_loop_kwargs = {\n\u001b[1;32m    285\u001b[0m             \u001b[0;34m\"cond\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtime_steps_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m   \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3056\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mreduced\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3057\u001b[0m   \"\"\"\n\u001b[0;32m-> 3058\u001b[0;31m   return reduce_max_with_dims(input_tensor, axis, keepdims, name,\n\u001b[0m\u001b[1;32m   3059\u001b[0m                               _ReductionDims(input_tensor, axis))\n",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_tensor, axis, keepdims, name, dims)\u001b[0m\n\u001b[1;32m   3066\u001b[0m                          dims=None):\n\u001b[1;32m   3067\u001b[0m   \u001b[0mkeepdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m   return _may_reduce_to_scalar(\n\u001b[1;32m   3069\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3070\u001b[0;31m       gen_math_ops._max(input_tensor, dims, keepdims, name=name))\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/cs757-final-project/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6331\u001b[0m         _ctx, \"Max\", name, input, axis, \"keep_dims\", keep_dims)\n\u001b[1;32m   6332\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6333\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6334\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6335\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6336\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6337\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m       return _max_eager_fallback(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wm_policy = make_world_model_policy(vae, mdnrnn, trained_controller)\n",
    "rewards, lengths = play_agent(env_name=\"Humanoid-v5\", model=wm_policy, n_timesteps=1000)\n",
    "np.sum(rewards), np.mean(lengths) #avg reward, avg episode length of world model policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc9415-0bc7-4468-8aca-f6fbf0d0c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(rewards), np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89646d66-98d6-4446-8a98-e4d2fe6a7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, lengths = play_agent(env_name=\"Humanoid-v5\", model=None, n_timesteps=1000)\n",
    "np.sum(rewards), np.mean(lengths) #avg reward, avg episode length of random policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fba6f0-89d1-404e-96d0-bf074e644be6",
   "metadata": {},
   "source": [
    "Okay, world models is still doing worse than random. Tough times! That said, we haven't done the magic of **scaling** yet! Let's break this bad boy up into a few scripts and hit the HPC!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3b6ff-7724-4a8c-9b6e-6bd192d09d04",
   "metadata": {},
   "source": [
    "### Epilogue: Saving MDN-RNNs and Controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c5ea3-5f3b-413f-9ac4-679f9ff84c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnrnn.save_weights('../models/mdnrnn/humanoid_10000_mdnrnn_model.weights.h5') #save ONLY weights -- much simpler than serializing the entire object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae7fba-3948-41ab-9cc2-ecbe694720fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mdnrnn = mdnrnn = MDNRNN(latent_dim=32, action_dim=17) #instantiate new model object \n",
    "new_mdnrnn(tf.zeros((1, 10, 49))) #invoke it to build its shape \n",
    "new_mdnrnn.load_weights('../models/mdnrnn/humanoid_10000_mdnrnn_model.weights.h5') #now load weights into empty vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6679f12-f1c4-4835-b163-8affba8c74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the controller's weights\n",
    "controller.save_weights('controller_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87982e54-d883-4adf-aa66-6a27ab085e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the controller\n",
    "new_controller = LinearController(input_dim=controller.linear.kernel.shape[0], action_dim=controller.linear.kernel.shape[1])\n",
    "\n",
    "new_controller.build((1,controller.linear.kernel.shape[0]))\n",
    "\n",
    "# Load the saved weights into the new controller instance\n",
    "new_controller.load_weights('controller_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b7e75-0c49-4472-b03b-d35d568b142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_policy = make_world_model_policy(vae, mdnrnn, new_controller)\n",
    "rewards, lengths = play_agent(env_name=\"Humanoid-v5\", model=wm_policy, n_timesteps=1000)\n",
    "np.sum(rewards), np.mean(lengths) #avg reward, avg episode length of world model policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs757-final-project",
   "language": "python",
   "name": "cs757-final-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
